{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.10.12 torch-2.2.2+cu118 CUDA:0 (NVIDIA GeForce RTX 3070, 8191MiB)\n",
      "Setup complete âœ… (16 CPUs, 23.5 GB RAM, 93.4/1006.9 GB disk)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2+cu118\n",
      "CUDA Available: True\n",
      "11.8\n",
      "Number of GPUs available: 1\n",
      "GPU 0 : NVIDIA GeForce RTX 3070\n",
      "Home:  /home/johnny/course/cs4442/final/yolov8\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import display\n",
    "from glob import glob\n",
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import xml.etree.ElementTree as etree\n",
    "\n",
    "IMAGE_SIZE = 640\n",
    "\n",
    "ultralytics.checks()\n",
    "\n",
    "print(torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(\"GPU\", i, \":\", torch.cuda.get_device_name(i))\n",
    "\n",
    "print(\"Home: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images directory exists: True\n",
      "Annotations directory exists: True\n",
      "['Cars113.png']\n",
      "['Cars239.xml']\n"
     ]
    }
   ],
   "source": [
    "base_dir = './datasets/'\n",
    "images_folder = base_dir + \"images/\"\n",
    "annotations_folder = base_dir + \"annotations/\"\n",
    "\n",
    "print(\"Images directory exists:\", os.path.exists(images_folder))\n",
    "print(\"Annotations directory exists:\", os.path.exists(annotations_folder))\n",
    "\n",
    "print(os.listdir(images_folder)[:1]) \n",
    "print(os.listdir(annotations_folder)[:1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'train', 'images', 'annotations', 'val']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train': ['labels.cache', 'images', 'labels'],\n",
       " 'test': ['images', 'labels'],\n",
       " 'val': ['labels.cache', 'images', 'labels']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the names of the directories to create.\n",
    "dirs_to_create = ['train', 'test', 'val']\n",
    "subdirs_to_create = ['images', 'labels']\n",
    "\n",
    "for dir_name in dirs_to_create:\n",
    "    dir_path = os.path.join(base_dir, dir_name)\n",
    "    \n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "for main_dir in dirs_to_create:  \n",
    "    for subdir in subdirs_to_create:  \n",
    "        subdir_path = os.path.join(base_dir, main_dir, subdir)\n",
    "        if not os.path.exists(subdir_path):\n",
    "            os.makedirs(subdir_path)\n",
    "\n",
    "created_dirs = os.listdir(base_dir)\n",
    "created_subdirs = {main_dir: os.listdir(os.path.join(base_dir, main_dir)) for main_dir in dirs_to_create}\n",
    "\n",
    "display(created_dirs)\n",
    "display(created_subdirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_images': 276,\n",
       " 'val_images': 70,\n",
       " 'test_images': 87,\n",
       " 'train_annotations': 552,\n",
       " 'val_annotations': 140,\n",
       " 'test_annotations': 174}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_files = sorted(glob.glob(os.path.join(images_folder, '*.png')))\n",
    "annotation_files = sorted(glob.glob(os.path.join(annotations_folder, '*.xml')))\n",
    "\n",
    "train_images, test_images, train_annotations, test_annotations = train_test_split(image_files, annotation_files, test_size=0.2, random_state=42)\n",
    "train_images, val_images, train_annotations, val_annotations = train_test_split(train_images, train_annotations, test_size=0.2, random_state=42)\n",
    "\n",
    "def copy_files(files, target_dir):\n",
    "    for file in files:\n",
    "        shutil.copy(file, target_dir)\n",
    "\n",
    "copy_files(train_images, os.path.join(base_dir, 'train', 'images'))\n",
    "copy_files(val_images, os.path.join(base_dir, 'val', 'images'))\n",
    "copy_files(test_images, os.path.join(base_dir, 'test', 'images'))\n",
    "\n",
    "copy_files(train_annotations, os.path.join(base_dir, 'train', 'labels'))\n",
    "copy_files(val_annotations, os.path.join(base_dir, 'val', 'labels'))\n",
    "copy_files(test_annotations, os.path.join(base_dir, 'test', 'labels'))\n",
    "\n",
    "num_files_copied = {\n",
    "    'train_images': len(os.listdir(os.path.join(base_dir, 'train', 'images'))),\n",
    "    'val_images': len(os.listdir(os.path.join(base_dir, 'val', 'images'))),\n",
    "    'test_images': len(os.listdir(os.path.join(base_dir, 'test', 'images'))),\n",
    "    'train_annotations': len(os.listdir(os.path.join(base_dir, 'train', 'labels'))),\n",
    "    'val_annotations': len(os.listdir(os.path.join(base_dir, 'val', 'labels'))),\n",
    "    'test_annotations': len(os.listdir(os.path.join(base_dir, 'test', 'labels')))\n",
    "}\n",
    "display(num_files_copied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[500, 268, 226, 125, 419, 173]]\n",
      "0 0.645 0.5559701492537313 0.386 0.1791044776119403\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parse(xml):\n",
    "    tree = etree.parse(xml)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    xmax = xmin = ymax = ymin = 0\n",
    "\n",
    "    size = root.find('size')\n",
    "    width = int(size.find('width').text)\n",
    "    height = int(size.find('height').text)\n",
    "\n",
    "    res = []\n",
    "    for object in root.iter('object'):\n",
    "        bndbox = object.find('bndbox')\n",
    "        xmin = int(bndbox.find(\"xmin\").text)\n",
    "        ymin = int(bndbox.find(\"ymin\").text)\n",
    "        xmax = int(bndbox.find(\"xmax\").text)\n",
    "        ymax = int(bndbox.find(\"ymax\").text)\n",
    "        res.append([width, height, xmin, ymin, xmax, ymax])\n",
    "\n",
    "    return res\n",
    "\n",
    "def normalize_for_yolo(original_width, original_height, xmin, ymin, xmax, ymax):\n",
    "    x_center = (xmin + xmax) / 2 / original_width\n",
    "    y_center = (ymin + ymax) / 2 / original_height\n",
    "    width = (xmax - xmin) / original_width\n",
    "    height = (ymax - ymin) / original_height\n",
    "    \n",
    "    return f\"0 {x_center} {y_center} {width} {height}\\n\"\n",
    "\n",
    "labels = parse('./datasets/annotations/Cars0.xml')\n",
    "print(labels)\n",
    "print(normalize_for_yolo(*(parse('./datasets/annotations/Cars0.xml')[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './datasets'\n",
    "for dir in dirs_to_create:\n",
    "    annotations_path = os.path.join(base_dir, dir, 'labels')\n",
    "    xml_files = [f for f in os.listdir(annotations_path) if f.endswith('.xml')]\n",
    "    \n",
    "    for xml_file in xml_files:\n",
    "        xml_path = os.path.join(annotations_path, xml_file)\n",
    "        labels = parse(xml_path)\n",
    "\n",
    "        txt_filename = os.path.splitext(xml_file)[0] + '.txt'\n",
    "        txt_path = os.path.join(annotations_path, txt_filename)\n",
    "        \n",
    "        data_str = []\n",
    "        for label in labels:\n",
    "            data_str.append(normalize_for_yolo(*label))\n",
    "        \n",
    "        with open(txt_path, 'w') as file:\n",
    "            file.writelines(data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = './data.yaml'\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "backbone = YOLO('./yolov8n.pt')\n",
    "\n",
    "results = backbone.train(data=dataset, epochs=100, batch=8, imgsz=IMAGE_SIZE, device='0', plots=True, cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.10.12 torch-2.2.2+cu118 CUDA:0 (NVIDIA GeForce RTX 3070, 8191MiB)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/johnny/course/cs4442/final/yolov8/datasets/val/labels.cache... 70 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB True): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:00<00:00, 699.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 12.05it/s]\n",
      "                   all         70         83      0.903      0.785       0.89      0.592\n",
      "Speed: 0.3ms preprocess, 2.4ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "best = YOLO('./runs/detect/train/weights/best.pt')\n",
    "\n",
    "results = best.val(data=dataset, epochs=100, batch=8, imgsz=IMAGE_SIZE, device=0, plots=True, cache=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
